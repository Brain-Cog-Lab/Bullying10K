{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve ,average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    " \n",
    "recall,precision,_=np.load(\"pr.npy\",allow_pickle=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "# 绘制每个类别的 PR 曲线\n",
    "for i in range(10):\n",
    "    \n",
    "    plt.plot(recall[i], precision[i], label=f'Class {i}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单文件转换 \n",
    "import json,os\n",
    "import numpy as np\n",
    "def allfile(path):\n",
    "    fileall=[]\n",
    "    for curpath,dirlist,filelist in os.walk(path):\n",
    "        for i in filelist:\n",
    "            fileall.append(os.path.join(curpath, i))\n",
    "             \n",
    "            \n",
    "    return fileall\n",
    "root='/home/dongyiting/datasets/pose_estimation/'\n",
    "\n",
    "fileall=allfile(root)\n",
    "count=0\n",
    "idx=0\n",
    "# print((fileall[0]))\n",
    "for file in fileall:\n",
    "\n",
    "    \n",
    "    # 读取JSON文件\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    path=file[len(root):].replace(\".json\",\"/\")\n",
    "     \n",
    "\n",
    "\n",
    "    fulldata=dict()\n",
    "    fulldata['images']=[]\n",
    "    fulldata['annotations']=[]\n",
    "    fulldata['categories']=[ {'id': 1, 'name': 'person'}]\n",
    "    \n",
    "    # print(data)\n",
    "    dictkey={}\n",
    "\n",
    "    alldd=[]\n",
    "    for d in data:\n",
    "\n",
    "        name=d[\"image_id\"]\n",
    "        height=260\n",
    "        width=346\n",
    "        id=int(d[\"image_id\"].replace(\".jpg\",\"\")) \n",
    "\n",
    "        if id not in dictkey:\n",
    "            dictkey[id]=id\n",
    "            fulldata['images'].append( {\"file_name\":path+name, \"height\":height, \"width\":width,\"id\":id} )\n",
    " \n",
    "        dataann=d\n",
    "        dataann['segmentation']=[[0]]\n",
    "        dataann['num_keypoints']=len(d[\"keypoints\"])//3\n",
    "\n",
    "\n",
    "        ll=[i for i in range(26*3) if i%3==2]\n",
    "        \n",
    "        dd=np.array(dataann[\"keypoints\"])\n",
    "        dd[np.logical_and( dd>0.2 , dd<1)] =2\n",
    "        dd[np.logical_and( dd<0.2 , dd<1)] =0\n",
    "        dd=dd.astype(np.int16)\n",
    "        dataann[\"keypoints\"]=dd.tolist()\n",
    "        dataann[\"image_id\"]=id\n",
    "        # print(dataann[\"keypoints\"])\n",
    "       \n",
    "        # alldd.append(dd[ll])\n",
    "\n",
    "        \n",
    "\n",
    "        dataann['area']=d['box'][-1]*d['box'][-2]\n",
    "        dataann['bbox']=d['box'] \n",
    "        dataann['iscrowd']=0\n",
    "        dataann['id']=count\n",
    "        count+=1\n",
    "        fulldata['annotations'].append(dataann)\n",
    "    path=file.replace(\"pose_estimation\",\"pose_estimation_coco\")\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(fulldata, f)\n",
    "         \n",
    "    \n",
    "    print(idx)\n",
    "    idx+=1\n",
    "    # if idx>1000:\n",
    "    #     dd=np.histogram(alldd,bins=50,range=[0,1] )\n",
    "    #     print(dd)\n",
    "    #     break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单文件转换 \n",
    "import json,os\n",
    "import numpy as np\n",
    "def allfile(path):\n",
    "    fileall=[]\n",
    "    for curpath,dirlist,filelist in os.walk(path):\n",
    "        for i in filelist:\n",
    "            fileall.append(os.path.join(curpath, i))\n",
    "             \n",
    "            \n",
    "    return fileall\n",
    "root='/home/dongyiting/datasets/pose_estimation/'\n",
    "\n",
    "fileall=allfile(root)\n",
    "count=0\n",
    "idx=0\n",
    "fulldata=dict()\n",
    "fulldata['images']=[]\n",
    "fulldata['annotations']=[]\n",
    "fulldata['categories']=[ {'id': 1, 'name': 'person'}]\n",
    "val=False\n",
    "# val=True\n",
    "\n",
    "validx=np.zeros(len(fileall),dtype=bool)\n",
    "validx[range(0,len(fileall),5)]=1\n",
    "\n",
    "if val:fileall=np.array(fileall)[validx]\n",
    "else:fileall=np.array(fileall)[~validx]\n",
    "\n",
    "# print((fileall[0]))\n",
    "for file in fileall:\n",
    "\n",
    "  \n",
    "    # 读取JSON文件\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    path=file[len(root):].replace(\".json\",\"/\")\n",
    "     \n",
    "    # 读取JSON文件\n",
    "    length=len(allfile(\"/data/datasets/Bullying10k_eventimage/\"+path))\n",
    "\n",
    "    # print(len(allfile(\"/data/datasets/Bullying10k_eventimage/\"+path)))\n",
    "    # continue\n",
    "    # print(data)\n",
    "    dictkey={}\n",
    "\n",
    "    alldd=[]\n",
    "    for d in data:\n",
    "\n",
    "        name=d[\"image_id\"].replace(\".jpg\",\".png\")\n",
    "        height=260\n",
    "        width=346\n",
    "        id=idx*1000+int(d[\"image_id\"].replace(\".jpg\",\"\")) \n",
    "        if int(d[\"image_id\"].replace(\".jpg\",\"\"))>=length:\n",
    "            break\n",
    "        if id not in dictkey:\n",
    "            dictkey[id]=id\n",
    "            fulldata['images'].append( {\"file_name\":path+name, \"height\":height, \"width\":width,\"id\":id} )\n",
    " \n",
    "        dataann=d\n",
    "        dataann['segmentation']=[[0]]\n",
    "        dataann['num_keypoints']=len(d[\"keypoints\"])//3\n",
    "\n",
    "\n",
    "        ll=[i for i in range(26*3) if i%3==2]\n",
    "        \n",
    "        dd=np.array(dataann[\"keypoints\"])\n",
    "        dd[np.logical_and( dd>0.2 , dd<1)] =2\n",
    "        dd[np.logical_and( dd<0.2 , dd<1)] =0\n",
    "        dd=dd.astype(np.int16)\n",
    "        dataann[\"keypoints\"]=dd.tolist()\n",
    "        dataann[\"image_id\"]=id\n",
    "\n",
    "        # print(dataann )\n",
    "        # break\n",
    "       \n",
    "        # alldd.append(dd[ll])\n",
    "\n",
    "        \n",
    "\n",
    "        dataann['area']=d['box'][-1]*d['box'][-2]\n",
    "        dataann['bbox']=d['box'] \n",
    "        dataann['iscrowd']=0\n",
    "        dataann['id']=count\n",
    "        count+=1\n",
    "        fulldata['annotations'].append(dataann)\n",
    "    # path=file.replace(\"pose_estimation\",\"pose_estimation_coco\")\n",
    "    # with open(path, 'w') as f:\n",
    "    #     json.dump(fulldata, f)\n",
    "         \n",
    "    # break\n",
    "    # print(idx)\n",
    "    idx+=1\n",
    "if val:\n",
    "    with open(\"/data/datasets/Bullying10k_eventimage/val_keypoints.json\", 'w') as f:\n",
    "        json.dump(fulldata, f)\n",
    "else:\n",
    "    with open(\"/data/datasets/Bullying10k_eventimage/train_keypoints.json\", 'w') as f:\n",
    "        json.dump(fulldata, f)\n",
    "    # if idx>1000:\n",
    "     \n",
    "    #     print(fulldata[\"images\"][0])\n",
    "    #     break\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
